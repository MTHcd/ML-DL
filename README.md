## Project Overview
This project integrates human feedback into the training of Large Language Models (LLMs) using Reinforcement Learning (RL). We aim to enhance Transformer-based models (like GPT) by incorporating human feedback to improve accuracy and contextual relevance.

## Project's goals
Implement Transformer models.
Train a reward model.
Optimize with PPO.
Generate outputs and validate performance.

## Methodology


## Significant findings
